{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764cf7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1577e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efc159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "device_select: auto\n",
      "model:\n",
      "  feature_extractor:\n",
      "    args:\n",
      "      cache_dir: ../data/FAUST_r/diffusion\n",
      "      in_channels: 128\n",
      "      input_type: wks\n",
      "      out_channels: 256\n",
      "    name: DiffusionNet\n",
      "  fm_solver:\n",
      "    args:\n",
      "      \n",
      "    name: RegularizedFMNet\n",
      "  name: URSSM\n",
      "  permutation:\n",
      "    args:\n",
      "      tau: 0.07\n",
      "    name: Similarity\n",
      "path: ../experiment/test-250605\n",
      "test:\n",
      "  dataset:\n",
      "    aug:\n",
      "      args:\n",
      "        footprint_wrap_folder: data/processed/footprint-wrap/\n",
      "        img_size: 5\n",
      "        l_mask_path: data/processed/left_foot_mask.png\n",
      "        pedar_dynamic_path: data/processed/pedar_dynamic.pkl\n",
      "        sense_range: 600\n",
      "        stack_range: 50\n",
      "      dataloader:\n",
      "        args:\n",
      "          batch_size: 128\n",
      "          shuffle: True\n",
      "        name: DataLoader\n",
      "      name: Footprint2Pressure_SensorStack_Blend\n",
      "    wo_aug:\n",
      "      args:\n",
      "        footprint_wrap_folder: data/processed/footprint-wrap/\n",
      "        img_size: 5\n",
      "        l_mask_path: data/processed/left_foot_mask.png\n",
      "        pedar_dynamic_path: data/processed/pedar_dynamic.pkl\n",
      "        sense_range: 600\n",
      "        stack_range: 50\n",
      "      dataloader:\n",
      "        args:\n",
      "          batch_size: 128\n",
      "          shuffle: True\n",
      "        name: DataLoader\n",
      "      name: Footprint2Pressure_SensorStack\n",
      "  metric:\n",
      "    MAE:\n",
      "      args:\n",
      "        \n",
      "      name: L1Loss\n",
      "    MSE:\n",
      "      args:\n",
      "        \n",
      "      name: MSELoss\n",
      "  script: TestScript\n",
      "train:\n",
      "  dataset:\n",
      "    test:\n",
      "      args:\n",
      "        data_root: data/FAUST_r/\n",
      "        num_evecs: 200\n",
      "        phase: test\n",
      "        return_corr: false\n",
      "        return_dist: false\n",
      "        return_evecs: true\n",
      "        return_faces: true\n",
      "      dataloader:\n",
      "        args:\n",
      "          batch_size: 1\n",
      "          shuffle: True\n",
      "        name: DataLoader\n",
      "      name: PairFaustDataset\n",
      "    train:\n",
      "      args:\n",
      "        data_root: data/FAUST_r/\n",
      "        num_evecs: 200\n",
      "        phase: train\n",
      "        return_corr: false\n",
      "        return_dist: false\n",
      "        return_evecs: true\n",
      "        return_faces: true\n",
      "      dataloader:\n",
      "        args:\n",
      "          batch_size: 1\n",
      "          shuffle: True\n",
      "        name: DataLoader\n",
      "      name: PairFaustDataset\n",
      "  loss:\n",
      "    align_loss:\n",
      "      args:\n",
      "        \n",
      "      name: SpatialSpectralAlignmentLoss_wrap\n",
      "      weight: 1.0\n",
      "    surfm_loss:\n",
      "      args:\n",
      "        w_bij: 1.0\n",
      "        w_lap: 0.0\n",
      "        w_orth: 1.0\n",
      "      name: SURFMNetLoss_wrap\n",
      "      weight: 1.0\n",
      "  metric:\n",
      "    geodist:\n",
      "      args:\n",
      "        \n",
      "      name: GeodesicDist\n",
      "  optimizer:\n",
      "    args:\n",
      "      lr: 0.001\n",
      "    epochs: 1\n",
      "    name: Adam\n",
      "  script: TrainScript\n"
     ]
    }
   ],
   "source": [
    "from src.infra import config\n",
    "\n",
    "path = '../experiment/test-250605'\n",
    "opt = config.load_config(path)\n",
    "opt.path = path\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0feee111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bccb69",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8c8382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset': torch.utils.data.dataset.Dataset,\n",
       " 'SingleFaustDataset': src.dataset.shape_cor.SingleFaustDataset,\n",
       " 'SingleScapeDataset': src.dataset.shape_cor.SingleScapeDataset,\n",
       " 'SingleShrec19Dataset': src.dataset.shape_cor.SingleShrec19Dataset,\n",
       " 'SingleSmalDataset': src.dataset.shape_cor.SingleSmalDataset,\n",
       " 'SingleDT4DDataset': src.dataset.shape_cor.SingleDT4DDataset,\n",
       " 'SingleShrec20Dataset': src.dataset.shape_cor.SingleShrec20Dataset,\n",
       " 'SingleTopKidsDataset': src.dataset.shape_cor.SingleTopKidsDataset,\n",
       " 'PairDataset': src.dataset.shape_cor.PairDataset,\n",
       " 'PairFaustDataset': src.dataset.shape_cor.PairFaustDataset,\n",
       " 'PairScapeDataset': src.dataset.shape_cor.PairScapeDataset,\n",
       " 'PairShrec19Dataset': src.dataset.shape_cor.PairShrec19Dataset,\n",
       " 'PairSmalDataset': src.dataset.shape_cor.PairSmalDataset,\n",
       " 'PairDT4DDataset': src.dataset.shape_cor.PairDT4DDataset,\n",
       " 'PairShrec20Dataset': src.dataset.shape_cor.PairShrec20Dataset,\n",
       " 'PairShrec16Dataset': src.dataset.shape_cor.PairShrec16Dataset,\n",
       " 'PairTopKidsDataset': src.dataset.shape_cor.PairTopKidsDataset}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src\n",
    "from src.infra.registry import DATASET_REGISTRY\n",
    "DATASET_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1b0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DATASET_REGISTRY['PairFaustDataset'](\n",
    "    phase='train',\n",
    "    data_root='../data/FAUST_r/',\n",
    "    return_evecs='true',\n",
    "    return_faces='true',\n",
    "    num_evecs=200,\n",
    "    return_corr='false',\n",
    "    return_dist='false',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83a25d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataLoader': torch.utils.data.dataloader.DataLoader}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.infra.registry import DATALOADER_REGISTRY\n",
    "DATALOADER_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2b2bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7faa24a83100>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DATALOADER_REGISTRY['DataLoader'](\n",
    "    dataset=dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dabdd7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tr_reg_026'] ['tr_reg_016']\n"
     ]
    }
   ],
   "source": [
    "from src.utils.tensor import to_device\n",
    "\n",
    "for batch, data in enumerate(dataloader):\n",
    "    data = to_device(data, device)\n",
    "    data_x, data_y = data['first'], data['second']\n",
    "    print(data_x['name'], data_y['name'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26747d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c4202e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Similarity': src.model.permutation.Similarity,\n",
       " 'RegularizedFMNet': src.model.fmap.RegularizedFMNet,\n",
       " 'URSSM': src.model.urssm.URSSM,\n",
       " 'DiffusionNet': src.model.diffusionnet.DiffusionNet}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.infra.registry import MODEL_REGISTRY\n",
    "MODEL_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6165e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URSSM(\n",
       "  (feature_extractor): DiffusionNet(\n",
       "    (first_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (last_linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0): DiffusionNetBlock(\n",
       "        (diffusion): LearnedTimeDiffusion()\n",
       "        (gradient_features): SpatialGradientFeatures(\n",
       "          (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (mlp): MiniMLP(\n",
       "          (miniMLP_linear_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (miniMLP_activation_000): ReLU()\n",
       "          (miniMLP_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "          (miniMLP_linear_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (miniMLP_activation_001): ReLU()\n",
       "          (miniMLP_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "          (miniMLP_linear_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DiffusionNetBlock(\n",
       "        (diffusion): LearnedTimeDiffusion()\n",
       "        (gradient_features): SpatialGradientFeatures(\n",
       "          (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (mlp): MiniMLP(\n",
       "          (miniMLP_linear_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (miniMLP_activation_000): ReLU()\n",
       "          (miniMLP_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "          (miniMLP_linear_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (miniMLP_activation_001): ReLU()\n",
       "          (miniMLP_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "          (miniMLP_linear_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): DiffusionNetBlock(\n",
       "        (diffusion): LearnedTimeDiffusion()\n",
       "        (gradient_features): SpatialGradientFeatures(\n",
       "          (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (mlp): MiniMLP(\n",
       "          (miniMLP_linear_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (miniMLP_activation_000): ReLU()\n",
       "          (miniMLP_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "          (miniMLP_linear_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (miniMLP_activation_001): ReLU()\n",
       "          (miniMLP_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "          (miniMLP_linear_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): DiffusionNetBlock(\n",
       "        (diffusion): LearnedTimeDiffusion()\n",
       "        (gradient_features): SpatialGradientFeatures(\n",
       "          (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (mlp): MiniMLP(\n",
       "          (miniMLP_linear_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (miniMLP_activation_000): ReLU()\n",
       "          (miniMLP_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "          (miniMLP_linear_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (miniMLP_activation_001): ReLU()\n",
       "          (miniMLP_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "          (miniMLP_linear_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fm_solver): RegularizedFMNet()\n",
       "  (permutation): Similarity()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urssm = MODEL_REGISTRY[opt.model.name](opt).to(device)\n",
    "urssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d0c19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrain weights from ../checkpoints/faust.pth\n"
     ]
    }
   ],
   "source": [
    "network_path = '../checkpoints/faust.pth'\n",
    "urssm.feature_extractor.load_state_dict(\n",
    "    torch.load(network_path)['networks']['feature_extractor']\n",
    ")\n",
    "print(f'Loaded pretrain weights from {network_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a597d89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cxy': tensor([[[ 9.8195e-01, -2.7259e-02, -2.3912e-02,  ...,  1.0097e-03,\n",
       "           -7.2692e-04, -4.9136e-04],\n",
       "          [-2.7238e-02, -9.9226e-01, -1.9070e-02,  ..., -6.5598e-05,\n",
       "           -1.0207e-04, -9.1797e-04],\n",
       "          [ 1.3511e-02,  1.8678e-02, -9.7463e-01,  ...,  3.5356e-04,\n",
       "           -2.2927e-04,  3.7693e-04],\n",
       "          ...,\n",
       "          [ 1.9589e-03,  1.5950e-03,  1.0679e-04,  ...,  1.4746e-01,\n",
       "            4.8278e-02,  1.9952e-01],\n",
       "          [-5.8314e-06, -1.9600e-04, -4.7687e-04,  ...,  3.2928e-02,\n",
       "           -6.9109e-02,  6.7890e-02],\n",
       "          [-7.9379e-04, -9.3708e-04, -4.4316e-04,  ...,  1.7181e-01,\n",
       "            1.4124e-01,  3.1555e-01]]], device='cuda:0', grad_fn=<CatBackward0>),\n",
       " 'Cyx': tensor([[[ 9.4994e-01, -3.1547e-02, -3.1429e-02,  ...,  8.6229e-05,\n",
       "            5.8255e-04, -7.6243e-05],\n",
       "          [-1.3198e-02, -9.3600e-01,  2.1863e-02,  ..., -4.6648e-04,\n",
       "            3.1874e-04, -3.3835e-04],\n",
       "          [ 1.5444e-02, -1.8294e-02, -9.9469e-01,  ...,  5.3709e-04,\n",
       "            6.4694e-04,  3.7413e-04],\n",
       "          ...,\n",
       "          [-1.7127e-04,  2.7311e-04,  6.2155e-04,  ...,  1.9170e-01,\n",
       "            1.1106e-01,  2.3112e-01],\n",
       "          [ 1.2841e-03, -2.2256e-03,  4.5464e-04,  ...,  7.6887e-03,\n",
       "           -6.6159e-02,  2.1013e-02],\n",
       "          [-1.4023e-03, -4.2726e-06, -1.0010e-03,  ...,  1.7552e-01,\n",
       "            9.4835e-02,  2.8633e-01]]], device='cuda:0', grad_fn=<CatBackward0>),\n",
       " 'Pxy': tensor([[[1.3425e-03, 1.3497e-02, 2.7746e-05,  ..., 5.7627e-07,\n",
       "           1.2016e-06, 2.0467e-06],\n",
       "          [4.3521e-03, 5.1497e-02, 5.7285e-05,  ..., 1.8559e-06,\n",
       "           5.1269e-06, 4.4331e-06],\n",
       "          [2.6627e-03, 8.6237e-05, 1.5833e-01,  ..., 1.1440e-06,\n",
       "           1.1944e-06, 1.5481e-05],\n",
       "          ...,\n",
       "          [2.7860e-07, 5.2442e-07, 8.9174e-08,  ..., 5.4722e-02,\n",
       "           6.5256e-02, 4.6350e-07],\n",
       "          [5.5570e-07, 1.7436e-06, 1.3656e-06,  ..., 1.4170e-06,\n",
       "           1.0053e-06, 5.8661e-07],\n",
       "          [2.2167e-07, 1.0550e-07, 1.7984e-07,  ..., 3.1324e-07,\n",
       "           2.2977e-07, 8.1231e-08]]], device='cuda:0', grad_fn=<ExpBackward0>),\n",
       " 'Pyx': tensor([[[2.2043e-03, 3.2201e-03, 1.5432e-03,  ..., 1.8950e-06,\n",
       "           6.3046e-07, 1.5155e-06],\n",
       "          [3.2184e-02, 5.5336e-02, 7.2583e-05,  ..., 5.1805e-06,\n",
       "           2.8729e-06, 1.0475e-06],\n",
       "          [5.8639e-05, 5.4556e-05, 1.1811e-01,  ..., 7.8075e-07,\n",
       "           1.9942e-06, 1.5825e-06],\n",
       "          ...,\n",
       "          [9.5678e-07, 1.3886e-06, 6.7038e-07,  ..., 3.7639e-01,\n",
       "           1.6257e-06, 2.1655e-06],\n",
       "          [2.4203e-06, 4.6536e-06, 8.4921e-07,  ..., 5.4454e-01,\n",
       "           1.3991e-06, 1.9271e-06],\n",
       "          [5.2487e-06, 5.1230e-06, 1.4013e-05,  ..., 4.9242e-06,\n",
       "           1.0395e-06, 8.6739e-07]]], device='cuda:0', grad_fn=<ExpBackward0>)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer = urssm(data_x, data_y)\n",
    "infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0fa34",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3913d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSELoss': torch.nn.modules.loss.MSELoss,\n",
       " 'SquaredFrobeniusLoss': src.loss.fmap.SquaredFrobeniusLoss,\n",
       " 'SURFMNetLoss': src.loss.fmap.SURFMNetLoss,\n",
       " 'SURFMNetLoss_wrap': src.loss.fmap.SURFMNetLoss_wrap,\n",
       " 'SpatialSpectralAlignmentLoss': src.loss.fmap.SpatialSpectralAlignmentLoss,\n",
       " 'SpatialSpectralAlignmentLoss_wrap': src.loss.fmap.SpatialSpectralAlignmentLoss_wrap,\n",
       " 'PartialFmapsLoss': src.loss.fmap.PartialFmapsLoss,\n",
       " 'DirichletLoss': src.loss.dirichlet.DirichletLoss,\n",
       " 'CompositeLoss': src.loss.composite.CompositeLoss}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.infra.registry import LOSS_REGISTRY\n",
    "LOSS_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bdf5437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'surfm_loss': {'fn': SURFMNetLoss_wrap(\n",
       "    (squared_frobenius): SquaredFrobeniusLoss()\n",
       "  ),\n",
       "  'weight': 1.0},\n",
       " 'align_loss': {'fn': SpatialSpectralAlignmentLoss_wrap(\n",
       "    (squared_frobenius): SquaredFrobeniusLoss()\n",
       "  ),\n",
       "  'weight': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict = {}\n",
    "\n",
    "for name, loss in opt.train.loss.items():\n",
    "    loss_dict[name] = {\n",
    "        'fn': LOSS_REGISTRY[loss['name']](**loss['args']).to(device),\n",
    "        'weight': loss['weight'],\n",
    "    }\n",
    "\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1a08a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surfm_loss tensor(99.2401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "align_loss tensor(50.5304, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, loss in loss_dict.items():\n",
    "    print(name, loss['fn'](infer, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f946a",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abf7c7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1Loss': torch.nn.modules.loss.L1Loss,\n",
       " 'MSELoss': torch.nn.modules.loss.MSELoss,\n",
       " 'MeanDiffRatio': src.metric.stats.MeanDiffRatio,\n",
       " 'StdDiffRatio': src.metric.stats.StdDiffRatio,\n",
       " 'calculate_geodesic_error': <function src.metric.geodist.calculate_geodesic_error(dist_x, corr_x, corr_y, p2p, return_mean=True)>,\n",
       " 'GeodesicDist': src.metric.geodist.GeodesicDist,\n",
       " 'plot_pck': <function src.metric.geodist.plot_pck(geo_err, threshold=0.1, steps=40)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.infra.registry import METRIC_REGISTRY\n",
    "METRIC_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "807d1147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geodist': GeodesicDist()}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dict = {}\n",
    "\n",
    "for name, metric in opt.train.metric.items():\n",
    "    metric_dict[name] = METRIC_REGISTRY[metric['name']](**metric['args']).to(device)\n",
    "\n",
    "metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6467308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geodist 0.020181167870759964\n"
     ]
    }
   ],
   "source": [
    "for name, metric in metric_dict.items():\n",
    "    print(name, metric(infer, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1afff",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c35aaf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SGD': torch.optim.sgd.SGD,\n",
       " 'Adam': torch.optim.adam.Adam,\n",
       " 'AdamW': torch.optim.adamw.AdamW,\n",
       " 'RMSprop': torch.optim.rmsprop.RMSprop,\n",
       " 'Adagrad': torch.optim.adagrad.Adagrad,\n",
       " 'Adadelta': torch.optim.adadelta.Adadelta}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.infra.registry import OPTIMIZER_REGISTRY\n",
    "OPTIMIZER_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6746169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: False\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = OPTIMIZER_REGISTRY[opt.train.optimizer.name](\n",
    "    params=urssm.parameters(),\n",
    "    **opt.train.optimizer.args,\n",
    ")\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37b28c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 loss: 170.54812622070312\n",
      "batch 1 loss: 116.75547790527344\n",
      "batch 2 loss: 175.21177673339844\n",
      "batch 3 loss: 141.9226837158203\n",
      "batch 4 loss: 271.80230712890625\n",
      "batch 5 loss: 182.36788940429688\n",
      "batch 6 loss: 157.69952392578125\n",
      "batch 7 loss: 261.27020263671875\n",
      "batch 8 loss: 311.74053955078125\n",
      "batch 9 loss: 313.6375427246094\n",
      "batch 10 loss: 353.85198974609375\n",
      "batch 11 loss: 254.96670532226562\n"
     ]
    }
   ],
   "source": [
    "for batch, data in enumerate(dataloader):\n",
    "    data = to_device(data, device)\n",
    "    infer = urssm(data['first'], data['second'])\n",
    "    loss_val = 0\n",
    "    \n",
    "    for name, loss in loss_dict.items():\n",
    "        loss_value = loss['fn'](infer, data) * loss['weight']\n",
    "        loss_val += loss_value\n",
    "    \n",
    "    print(f'batch {batch} loss: {loss_val.item()}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac98d2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dongliang-cao-2023-cvpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
