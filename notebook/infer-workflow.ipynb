{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "323b603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2d51678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d8e6312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = 'output/init-sym-grid'\n",
    "# output_path = 'output/init-clr-grad'\n",
    "output_path = 'output/pretrain-sym-grid'\n",
    "# output_path = 'output/pretrain-clr-grad'\n",
    "\n",
    "texture_path = f'output/texture-sym-grid.png'\n",
    "# texture_path = f'output/texture-clr-grad.png'\n",
    "\n",
    "plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f8635",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "93518151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "896524da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset': torch.utils.data.dataset.Dataset,\n",
       " 'SingleFaustDataset': src.dataset.shape_cor.SingleFaustDataset,\n",
       " 'SingleScapeDataset': src.dataset.shape_cor.SingleScapeDataset,\n",
       " 'SingleShrec19Dataset': src.dataset.shape_cor.SingleShrec19Dataset,\n",
       " 'SingleSmalDataset': src.dataset.shape_cor.SingleSmalDataset,\n",
       " 'SingleDT4DDataset': src.dataset.shape_cor.SingleDT4DDataset,\n",
       " 'SingleShrec20Dataset': src.dataset.shape_cor.SingleShrec20Dataset,\n",
       " 'SingleTopKidsDataset': src.dataset.shape_cor.SingleTopKidsDataset,\n",
       " 'PairDataset': src.dataset.shape_cor.PairDataset,\n",
       " 'PairFaustDataset': src.dataset.shape_cor.PairFaustDataset,\n",
       " 'PairScapeDataset': src.dataset.shape_cor.PairScapeDataset,\n",
       " 'PairShrec19Dataset': src.dataset.shape_cor.PairShrec19Dataset,\n",
       " 'PairSmalDataset': src.dataset.shape_cor.PairSmalDataset,\n",
       " 'PairDT4DDataset': src.dataset.shape_cor.PairDT4DDataset,\n",
       " 'PairShrec20Dataset': src.dataset.shape_cor.PairShrec20Dataset,\n",
       " 'PairShrec16Dataset': src.dataset.shape_cor.PairShrec16Dataset,\n",
       " 'PairTopKidsDataset': src.dataset.shape_cor.PairTopKidsDataset}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.infra.registry import DATASET_REGISTRY\n",
    "DATASET_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "589ae1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.tensor import to_device\n",
    "\n",
    "dataset = DATASET_REGISTRY['PairFaustDataset'](\n",
    "    phase='train',\n",
    "    data_root='../data/FAUST_r/',\n",
    "    return_evecs='true',\n",
    "    return_faces='true',\n",
    "    num_evecs=200,\n",
    "    return_corr='false',\n",
    "    return_dist='false',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0bcd774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tr_reg_000', 'tr_reg_001')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\n",
    "data = dataset[1]\n",
    "data_x, data_y = to_device(data['first'], device), to_device(data['second'], device)\n",
    "data_x['name'], data_y['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f55f01",
   "metadata": {},
   "source": [
    "## Model components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d61e6",
   "metadata": {},
   "source": [
    "### DiffusionNet feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e517eb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Similarity': src.model.permutation.Similarity,\n",
       " 'RegularizedFMNet': src.model.fmap.RegularizedFMNet,\n",
       " 'DiffusionNet': src.model.diffusionnet.DiffusionNet}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src\n",
    "from src.infra.registry import MODEL_REGISTRY\n",
    "MODEL_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6d0d198d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionNet(\n",
       "  (first_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (last_linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (blocks): ModuleList(\n",
       "    (0): DiffusionNetBlock(\n",
       "      (diffusion): LearnedTimeDiffusion()\n",
       "      (gradient_features): SpatialGradientFeatures(\n",
       "        (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (mlp): MiniMLP(\n",
       "        (miniMLP_linear_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "        (miniMLP_activation_000): ReLU()\n",
       "        (miniMLP_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "        (miniMLP_linear_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (miniMLP_activation_001): ReLU()\n",
       "        (miniMLP_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "        (miniMLP_linear_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DiffusionNetBlock(\n",
       "      (diffusion): LearnedTimeDiffusion()\n",
       "      (gradient_features): SpatialGradientFeatures(\n",
       "        (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (mlp): MiniMLP(\n",
       "        (miniMLP_linear_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "        (miniMLP_activation_000): ReLU()\n",
       "        (miniMLP_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "        (miniMLP_linear_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (miniMLP_activation_001): ReLU()\n",
       "        (miniMLP_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "        (miniMLP_linear_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): DiffusionNetBlock(\n",
       "      (diffusion): LearnedTimeDiffusion()\n",
       "      (gradient_features): SpatialGradientFeatures(\n",
       "        (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (mlp): MiniMLP(\n",
       "        (miniMLP_linear_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "        (miniMLP_activation_000): ReLU()\n",
       "        (miniMLP_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "        (miniMLP_linear_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (miniMLP_activation_001): ReLU()\n",
       "        (miniMLP_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "        (miniMLP_linear_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): DiffusionNetBlock(\n",
       "      (diffusion): LearnedTimeDiffusion()\n",
       "      (gradient_features): SpatialGradientFeatures(\n",
       "        (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (mlp): MiniMLP(\n",
       "        (miniMLP_linear_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "        (miniMLP_activation_000): ReLU()\n",
       "        (miniMLP_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "        (miniMLP_linear_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (miniMLP_activation_001): ReLU()\n",
       "        (miniMLP_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "        (miniMLP_linear_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = MODEL_REGISTRY['DiffusionNet'](\n",
    "    in_channels=128,\n",
    "    out_channels=256,\n",
    "    cache_dir='../data/FAUST_r/diffusion',\n",
    "    input_type='wks',\n",
    ").to(device)\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "460b809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrain weights from ../checkpoints/faust.pth\n"
     ]
    }
   ],
   "source": [
    "# load pretrain weights\n",
    "if 'pretrain' in output_path:\n",
    "    network_path = '../checkpoints/faust.pth'\n",
    "    feature_extractor.load_state_dict(\n",
    "        torch.load(network_path)['networks']['feature_extractor']\n",
    "    )\n",
    "    print(f'Loaded pretrain weights from {network_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a22c992e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4999, 256]), torch.Size([1, 5000, 256]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_x = feature_extractor(\n",
    "    data_x['verts'].unsqueeze(0),\n",
    "    data_x['faces'].unsqueeze(0),\n",
    ")\n",
    "\n",
    "feat_y = feature_extractor(\n",
    "    data_y['verts'].unsqueeze(0),\n",
    "    data_y['faces'].unsqueeze(0),\n",
    ")\n",
    "\n",
    "feat_x.shape, feat_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "64755655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4756, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare features computed from mesh and point cloud\n",
    "feat_x_pcd = feature_extractor(\n",
    "    data_x['verts'].unsqueeze(0),\n",
    "    # data_x['faces'].unsqueeze(0),\n",
    ")\n",
    "\n",
    "(feat_x - feat_x_pcd).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdbb2f",
   "metadata": {},
   "source": [
    "### Funtional maps solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d2481775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegularizedFMNet()"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_solver = MODEL_REGISTRY['RegularizedFMNet'](\n",
    "    bidirectional=True,\n",
    ").to(device)\n",
    "\n",
    "fm_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c48091c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_x = data_x['evals']\n",
    "evals_y = data_y['evals']\n",
    "evecs_x = data_x['evecs']\n",
    "evecs_y = data_y['evecs']\n",
    "evecs_trans_x = data_x['evecs_trans']\n",
    "evecs_trans_y = data_y['evecs_trans']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ae448",
   "metadata": {},
   "source": [
    "#### Eigen vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "17971f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4999, 200]), torch.Size([200, 4999]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evecs_x.shape, evecs_trans_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e619be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify eigen vectors' inverses\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.tensor import to_numpy\n",
    "\n",
    "if plot:\n",
    "    mul = evecs_x @ evecs_trans_x\n",
    "    plt.imshow(to_numpy(mul), vmin=mul.mean() - 3 * mul.std(), vmax=mul.mean() + 3 * mul.std())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f24a0",
   "metadata": {},
   "source": [
    "#### Functional maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a9101c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 200, 200]), torch.Size([1, 200, 200]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cxy, Cyx = fm_solver(\n",
    "    feat_x, feat_y,\n",
    "    evals_x.unsqueeze(0),\n",
    "    evals_y.unsqueeze(0),\n",
    "    evecs_trans_x.unsqueeze(0),\n",
    "    evecs_trans_y.unsqueeze(0),\n",
    ")\n",
    "\n",
    "Cxy.shape, Cyx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c2b86c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify inverse maps\n",
    "\n",
    "if plot:\n",
    "    plt.imshow(to_numpy((Cxy @ Cyx)[0]))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53367671",
   "metadata": {},
   "source": [
    "### Point-wise correspondence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4a5d280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = MODEL_REGISTRY['Similarity'](\n",
    "    tau=0.07,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c8ebbbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4999, 5000]),\n",
       " tensor(7.4791e-11, device='cuda:0', grad_fn=<MinBackward1>),\n",
       " tensor(0.8798, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       " tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0.0046, device='cuda:0', grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "similarity = torch.bmm(\n",
    "    F.normalize(feat_x, dim=-1, p=2),\n",
    "    F.normalize(feat_y, dim=-1, p=2).transpose(1, 2),\n",
    ")\n",
    "\n",
    "# sinkhorn normalization\n",
    "Pxy = permutation(similarity)\n",
    "Pyx = permutation(similarity.transpose(1, 2))\n",
    "\n",
    "Pxy.shape, Pxy.min(), Pxy.max(), Pxy.mean(), Pxy.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9b75d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot:\n",
    "    plt.imshow(to_numpy(Pxy), vmin=Pxy.min(), vmax=Pxy.mean() + 3 * Pxy.std())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6b7334b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot:\n",
    "    mul = Pxy @ Pyx\n",
    "    plt.imshow(to_numpy(mul), vmin=mul.min(), vmax=mul.mean() + 3 * mul.std())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2bfa4d",
   "metadata": {},
   "source": [
    "## Pre-refine evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b93afd",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fe3655ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSELoss': torch.nn.modules.loss.MSELoss,\n",
       " 'SquaredFrobeniusLoss': src.loss.fmap.SquaredFrobeniusLoss,\n",
       " 'SURFMNetLoss': src.loss.fmap.SURFMNetLoss,\n",
       " 'PartialFmapsLoss': src.loss.fmap.PartialFmapsLoss,\n",
       " 'DirichletLoss': src.loss.dirichlet.DirichletLoss}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.infra.registry import LOSS_REGISTRY\n",
    "dict = {}\n",
    "LOSS_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d1e67a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l_bij': 14.611942291259766, 'l_orth': 42.416934967041016}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surfm_loss = LOSS_REGISTRY['SURFMNetLoss'](\n",
    "    w_bij=1.0,\n",
    "    w_orth=1.0,\n",
    "    w_lap=0.0,\n",
    ")\n",
    "loss = surfm_loss(Cxy, Cyx, evals_x, evals_y)\n",
    "dict['l_bij'] = loss['l_bij'].item()\n",
    "dict['l_orth'] = loss['l_orth'].item()\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "13ef9125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l_bij': 14.611942291259766,\n",
       " 'l_orth': 42.416934967041016,\n",
       " 'align_loss': 25.071290969848633}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_loss = LOSS_REGISTRY['SquaredFrobeniusLoss'](\n",
    "    loss_weight=1.0,\n",
    ")\n",
    "\n",
    "Cxy_est = torch.bmm(\n",
    "    evecs_trans_y.unsqueeze(0),\n",
    "    torch.bmm(Pyx, evecs_x.unsqueeze(0)),\n",
    ")\n",
    "\n",
    "Cyx_est = torch.bmm(\n",
    "    evecs_trans_x.unsqueeze(0),\n",
    "    torch.bmm(Pxy, evecs_y.unsqueeze(0)),\n",
    ")\n",
    "\n",
    "dict['align_loss'] = align_loss(Cxy, Cxy_est).item()\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ff378732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l_bij': 14.611942291259766,\n",
       " 'l_orth': 42.416934967041016,\n",
       " 'align_loss': 25.071290969848633,\n",
       " 'dirichlet_loss': 32.860107421875}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet_loss = LOSS_REGISTRY['DirichletLoss'](\n",
    "    loss_weight=5,\n",
    ")\n",
    "Lx, Ly = data_x['L'], data_y['L']\n",
    "dict['dirichlet_loss'] = dirichlet_loss(torch.bmm(Pxy, data_y['verts'].unsqueeze(0)), Lx.unsqueeze(0)).item()\n",
    "dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe1e51",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d13c0a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1Loss': torch.nn.modules.loss.L1Loss,\n",
       " 'MSELoss': torch.nn.modules.loss.MSELoss,\n",
       " 'MeanDiffRatio': src.metric.stats.MeanDiffRatio,\n",
       " 'StdDiffRatio': src.metric.stats.StdDiffRatio,\n",
       " 'calculate_geodesic_error': <function src.metric.geodist.calculate_geodesic_error(dist_x, corr_x, corr_y, p2p, return_mean=True)>,\n",
       " 'plot_pck': <function src.metric.geodist.plot_pck(geo_err, threshold=0.1, steps=40)>}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.infra.registry import METRIC_REGISTRY\n",
    "METRIC_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cf027fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.fmap import fmap2pointmap\n",
    "\n",
    "p2p = fmap2pointmap(Cxy.squeeze(), evecs_x, evecs_y)\n",
    "p2p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "85b3c281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l_bij': 14.611942291259766,\n",
       " 'l_orth': 42.416934967041016,\n",
       " 'align_loss': 25.071290969848633,\n",
       " 'dirichlet_loss': 32.860107421875,\n",
       " 'geo_err_mean': 0.014561972}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_err = METRIC_REGISTRY['calculate_geodesic_error'](\n",
    "    dist_x=to_numpy(data_x['dist']),\n",
    "    corr_x=to_numpy(data_x['corr']),\n",
    "    corr_y=to_numpy(data_y['corr']),\n",
    "    p2p=to_numpy(p2p),\n",
    "    return_mean=False,\n",
    ")\n",
    "dict['geo_err_mean'] = geo_err.mean()\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3fd44ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot:\n",
    "    METRIC_REGISTRY['plot_pck'](geo_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5fb35cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_bij</th>\n",
       "      <th>l_orth</th>\n",
       "      <th>align_loss</th>\n",
       "      <th>dirichlet_loss</th>\n",
       "      <th>geo_err_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre-refine</th>\n",
       "      <td>14.611942</td>\n",
       "      <td>42.416935</td>\n",
       "      <td>25.071291</td>\n",
       "      <td>32.860107</td>\n",
       "      <td>0.014562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                l_bij     l_orth  align_loss  dirichlet_loss  geo_err_mean\n",
       "pre-refine  14.611942  42.416935   25.071291       32.860107      0.014562"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(dict, index=['pre-refine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f88b6",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7abcf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# copy texture file to output directory\n",
    "if plot:\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    texture_fname = os.path.basename(texture_path)\n",
    "    cp_texture_path = os.path.join(output_path, texture_fname)\n",
    "\n",
    "    shutil.copy(\n",
    "        texture_path,\n",
    "        cp_texture_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9a7a4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.texture import write_obj_pair\n",
    "\n",
    "# write the output obj files\n",
    "if plot:\n",
    "    name_x, name_y = data_x['name'], data_y['name']\n",
    "    file_x = os.path.join(output_path, f'{name_x}.obj')\n",
    "    file_y = os.path.join(output_path, f'{name_x}-{name_y}.obj')\n",
    "    faces_x, faces_y = to_numpy(data_x['faces']), to_numpy(data_y['faces'])\n",
    "    verts_x, verts_y = to_numpy(data_x['verts']), to_numpy(data_y['verts'])\n",
    "\n",
    "    write_obj_pair(file_x, file_y, verts_x, faces_x, verts_y, faces_y, to_numpy(Pyx), texture_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb62432a",
   "metadata": {},
   "source": [
    "## Test-time adaption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cff73d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_single(data, feature_extractor, fm_solver, permutation):\n",
    "    # data prep\n",
    "    data_x, data_y = to_device(data['first'], device), to_device(data['second'], device)\n",
    "\n",
    "    verts_x = data_x['verts'].unsqueeze(0)\n",
    "    verts_y = data_y['verts'].unsqueeze(0)\n",
    "    faces_x = data_x['faces'].unsqueeze(0)\n",
    "    faces_y = data_y['faces'].unsqueeze(0)\n",
    "    evals_x = data_x['evals'].unsqueeze(0)\n",
    "    evals_y = data_y['evals'].unsqueeze(0)\n",
    "    evecs_trans_x = data_x['evecs_trans'].unsqueeze(0)\n",
    "    evecs_trans_y = data_y['evecs_trans'].unsqueeze(0)\n",
    "\n",
    "    # feature extractor\n",
    "    feat_x = feature_extractor(verts_x, faces_x)\n",
    "    feat_y = feature_extractor(verts_y, faces_y)\n",
    "\n",
    "    # fm solver\n",
    "    Cxy, Cyx = fm_solver(\n",
    "        feat_x, feat_y,\n",
    "        evals_x,\n",
    "        evals_y,\n",
    "        evecs_trans_x,\n",
    "        evecs_trans_y,\n",
    "    )\n",
    "\n",
    "    # point-wise correspondence\n",
    "    similarity = torch.bmm(\n",
    "        F.normalize(feat_x, dim=-1, p=2),\n",
    "        F.normalize(feat_y, dim=-1, p=2).transpose(1, 2),\n",
    "    )\n",
    "\n",
    "    Pxy = permutation(similarity)\n",
    "    Pyx = permutation(similarity.transpose(1, 2))\n",
    "\n",
    "    return {\n",
    "        'Cxy': Cxy,\n",
    "        'Cyx': Cyx,\n",
    "        'Pxy': Pxy,\n",
    "        'Pyx': Pyx,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bdbeea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = infer_single(data, feature_extractor, fm_solver, permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "59eb5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_single(data, infer, surfm_loss, align_loss, dirichlet_loss):\n",
    "    # data prep\n",
    "    data_x, data_y = to_device(data['first'], device), to_device(data['second'], device)\n",
    "\n",
    "    verts_x = data_x['verts'].unsqueeze(0)\n",
    "    verts_y = data_y['verts'].unsqueeze(0)\n",
    "    evals_x = data_x['evals'].unsqueeze(0)\n",
    "    evals_y = data_y['evals'].unsqueeze(0)\n",
    "    evecs_x = data_x['evecs'].unsqueeze(0)\n",
    "    evecs_y = data_y['evecs'].unsqueeze(0)\n",
    "    evecs_trans_x = data_x['evecs_trans'].unsqueeze(0)\n",
    "    evecs_trans_y = data_y['evecs_trans'].unsqueeze(0)\n",
    "    Lx = data_x['L'].unsqueeze(0)\n",
    "    Ly = data_y['L'].unsqueeze(0)\n",
    "\n",
    "    Cxy = infer['Cxy']\n",
    "    Cyx = infer['Cyx']\n",
    "    Pxy = infer['Pxy']\n",
    "    Pyx = infer['Pyx']\n",
    "\n",
    "    dict = {}\n",
    "\n",
    "    # surfmnet loss\n",
    "\n",
    "    loss = surfm_loss(Cxy, Cyx, evals_x, evals_y)\n",
    "    dict['l_bij'] = loss['l_bij']\n",
    "    dict['l_orth'] = loss['l_orth']\n",
    "\n",
    "    # alignment loss\n",
    "    Cxy_est = torch.bmm(\n",
    "        evecs_trans_y,\n",
    "        torch.bmm(Pyx, evecs_x),\n",
    "    )\n",
    "\n",
    "    Cyx_est = torch.bmm(\n",
    "        evecs_trans_x,\n",
    "        torch.bmm(Pxy, evecs_y),\n",
    "    )\n",
    "\n",
    "    dict['align_loss_xy'] = align_loss(Cxy, Cxy_est)\n",
    "    dict['align_loss_yx'] = align_loss(Cyx, Cyx_est)\n",
    "\n",
    "    # dirichlet loss\n",
    "    dict['dirichlet_loss_x'] = dirichlet_loss(torch.bmm(Pxy, verts_y), Lx)\n",
    "    dict['dirichlet_loss_y'] = dirichlet_loss(torch.bmm(Pyx, verts_x), Ly)\n",
    "\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "04a7538b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l_bij': tensor(14.7971, device='cuda:0', grad_fn=<MulBackward0>),\n",
       " 'l_orth': tensor(42.9662, device='cuda:0', grad_fn=<MulBackward0>),\n",
       " 'align_loss_xy': tensor(24.9737, device='cuda:0', grad_fn=<MulBackward0>),\n",
       " 'align_loss_yx': tensor(23.6401, device='cuda:0', grad_fn=<MulBackward0>),\n",
       " 'dirichlet_loss_x': tensor(28.3958, device='cuda:0', grad_fn=<MulBackward0>),\n",
       " 'dirichlet_loss_y': tensor(42.1794, device='cuda:0', grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_single(data, infer, surfm_loss, align_loss, dirichlet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "36af3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optim_params = [\n",
    "    {'params': feature_extractor.parameters(), 'lr': 1.0e-3},\n",
    "    {'params': fm_solver.parameters(), 'lr': 1.0e-3},\n",
    "    {'params': permutation.parameters(), 'lr': 1.0e-3},\n",
    "]\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    optim_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4f126d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(138.3084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.3314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.3656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.4401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.4093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.0184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.4861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.8609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.4250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.5734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.2537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.0839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.6947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.5129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.6414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.2607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.7626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.6178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.3132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.3646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.3895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.1932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.9697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.9875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.9498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.3762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.3510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.2857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.1581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.1663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.7623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.9677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.2085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.5182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.0415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.4846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.6752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.2842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.6188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.9574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.4393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.4754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.2113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.6525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.7649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.3530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.6820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.7946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.3664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.0272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.3812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.0655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.7964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.6462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.1933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.8227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.8463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.7362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.5994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.5277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.1969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.2792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.2577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.1320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.7940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.5339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.8214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.2398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.5552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.1395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.9137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.4175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.3602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.9663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.1159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.9690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.5612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.7251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.4252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.5115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.6378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.8937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.7436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.7630, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    infer = infer_single(data, feature_extractor, fm_solver, permutation)\n",
    "    loss_dict = loss_single(data, infer, surfm_loss, align_loss, dirichlet_loss)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for k, v in loss_dict.items():\n",
    "        loss += v\n",
    "\n",
    "    print(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9b8f5e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013599425"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2p = fmap2pointmap(infer['Cxy'].squeeze(), evecs_x, evecs_y)\n",
    "geo_err = METRIC_REGISTRY['calculate_geodesic_error'](\n",
    "    dist_x=to_numpy(data_x['dist']),\n",
    "    corr_x=to_numpy(data_x['corr']),\n",
    "    corr_y=to_numpy(data_y['corr']),\n",
    "    p2p=to_numpy(p2p),\n",
    "    return_mean=False,\n",
    ")\n",
    "geo_err.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a83f1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(output_path, 'refine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "64321683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/pretrain-sym-grid/refine/texture-sym-grid.png'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(output_path, exist_ok=True)\n",
    "texture_fname = os.path.basename(texture_path)\n",
    "cp_texture_path = os.path.join(output_path, texture_fname)\n",
    "\n",
    "shutil.copy(\n",
    "    texture_path,\n",
    "    cp_texture_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fa18d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_x, name_y = data_x['name'], data_y['name']\n",
    "file_x = os.path.join(output_path, f'{name_x}.obj')\n",
    "file_y = os.path.join(output_path, f'{name_x}-{name_y}.obj')\n",
    "faces_x, faces_y = to_numpy(data_x['faces']), to_numpy(data_y['faces'])\n",
    "verts_x, verts_y = to_numpy(data_x['verts']), to_numpy(data_y['verts'])\n",
    "\n",
    "write_obj_pair(file_x, file_y, verts_x, faces_x, verts_y, faces_y, to_numpy(Pyx), texture_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881555b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dongliang-cao-2023-cvpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
