{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cd64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c810c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f2724b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848513d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from src.infra import config\n",
    "\n",
    "path = '../../config/vec.yaml'\n",
    "opt = config.load_config(path)\n",
    "opt.path = path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136a710",
   "metadata": {},
   "source": [
    "## Dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9128a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_root = Path('/home/knpob/Documents/Hinton/data/shape-corr/FAUST_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8675d402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset.shape_cor_fast import PairFaustDatasetFast\n",
    "\n",
    "dataset = PairFaustDatasetFast(\n",
    "    data_root=data_root,\n",
    "    phase='train',\n",
    "    return_faces=True,\n",
    "    return_L=True,\n",
    "    return_mass=True,\n",
    "    num_evecs=200,\n",
    "    return_evecs=True,\n",
    "    return_grad=True,\n",
    "    return_corr=True,\n",
    "    return_dist=False,\n",
    ")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55d6e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataloader.shape_cor_batch import BatchShapePairDataLoader\n",
    "\n",
    "dataloader = BatchShapePairDataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cae47d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000'],\n",
       " ['tr_reg_008',\n",
       "  'tr_reg_009',\n",
       "  'tr_reg_010',\n",
       "  'tr_reg_011',\n",
       "  'tr_reg_012',\n",
       "  'tr_reg_013',\n",
       "  'tr_reg_014',\n",
       "  'tr_reg_015'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, data in enumerate(dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "\n",
    "data['first']['name'], data['second']['name'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf078500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "         [4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "         [4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "         ...,\n",
       "         [4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "         [4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "         [4414, 1129, 1929,  ..., 3617,  173, 2482]]),\n",
       " tensor([[4466, 1211, 2037,  ..., 3712,  182, 2703],\n",
       "         [4414, 1138, 1930,  ..., 3604,  141, 2499],\n",
       "         [4420, 1137, 1903,  ..., 3627, 2400, 2591],\n",
       "         ...,\n",
       "         [4402, 1169, 1929,  ..., 3664,  160, 2617],\n",
       "         [4306, 1089, 1845,  ..., 3604,  146, 2490],\n",
       "         [4433, 1149, 1941,  ..., 3656,  180, 2601]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['first']['corr'], data['second']['corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1aac783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4998)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['first']['corr'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddc81bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "        [4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "        [4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "        ...,\n",
       "        [4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "        [4414, 1129, 1929,  ..., 3617,  173, 2482],\n",
       "        [4414, 1129, 1929,  ..., 3617,  173, 2482]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['first']['corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ea344bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5000])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "corr_x = data['first']['corr']   # [B, V]\n",
    "corr_y = data['second']['corr']  # [B, V]\n",
    "\n",
    "# template --> corr_x <-(row-wise corresponding)-> corr_y <-- target\n",
    "B, V_t = corr_x.shape\n",
    "batch_idx = torch.arange(B, device=corr_y.device).unsqueeze(1).expand(B, V_t)  # [B, V_t] P.S. V_t is the number of vertices in the template shape\n",
    "p2p_t = torch.full((B, V_t), -1, dtype=torch.long).to(device=corr_y.device)\n",
    "p2p_t[batch_idx, corr_y] = corr_x\n",
    "p2p_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1085ac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4999])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_x = data['first']['verts'].shape[1]\n",
    "p2p = torch.full((B, V_x), -1, dtype=torch.long).to(device=corr_y.device)\n",
    "p2p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00306421",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5000 is out of bounds for dimension 1 with size 4999",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mp2p\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_t\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m p2p_t[:, :V_x]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5000 is out of bounds for dimension 1 with size 4999"
     ]
    }
   ],
   "source": [
    "p2p[:, V_t] = p2p_t[:, :V_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db5d83cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.metric.infer_sample failed: Traceback (most recent call last):\n",
      "  File \"/home/knpob/miniconda3/envs/fmap/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/knpob/miniconda3/envs/fmap/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/knpob/miniconda3/envs/fmap/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/knpob/Documents/Humboldt/urssm-replicate/notebook/prototype/../../src/metric/infer_sample.py\", line 13, in <module>\n",
      "    class TextureTransferSample(BaseMetric):\n",
      "  File \"/home/knpob/Documents/Humboldt/urssm-replicate/notebook/prototype/../../src/infra/registry.py\", line 17, in register_fn\n",
      "    self.add(fn.__name__, fn)\n",
      "  File \"/home/knpob/Documents/Humboldt/urssm-replicate/notebook/prototype/../../src/infra/registry.py\", line 7, in add\n",
      "    assert (name not in self), f\"An object named '{name}' was already registered in {self.name} registry\"\n",
      "AssertionError: An object named 'TextureTransferSample' was already registered in metric registry\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   28,   96,  ...,   -1,   -1,   -1],\n",
       "        [   0, 2383,   96,  ...,   -1,   -1,   -1],\n",
       "        [   0, 2383,    2,  ..., 1949,   -1,   -1],\n",
       "        ...,\n",
       "        [  71,   16,    2,  ...,   -1,   -1,   -1],\n",
       "        [   0,   16,  118,  ..., 1949,   -1,   -1],\n",
       "        [  70,   28,  118,  ...,   -1,   -1,   -1]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.fmap import corr2pointmap_vectorized\n",
    "\n",
    "p2p = corr2pointmap_vectorized(\n",
    "    corr_x=data['first']['corr'],\n",
    "    corr_y=data['second']['corr'],\n",
    "    num_verts_y=max(data['second']['num_verts']),\n",
    ")\n",
    "p2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d0fd46d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (200) must match the size of tensor b (5001) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmap\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pointmap2Pyx_vectorized\n\u001b[0;32m----> 3\u001b[0m Pyx \u001b[38;5;241m=\u001b[39m \u001b[43mpointmap2Pyx_vectorized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp2p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp2p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevecs_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevecs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevecs_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msecond\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevecs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevecs_trans_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevecs_trans\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevecs_trans_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msecond\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevecs_trans\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverts_mask_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msecond\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mverts_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Humboldt/urssm-replicate/notebook/prototype/../../src/utils/fmap.py:152\u001b[0m, in \u001b[0;36mpointmap2Pyx_vectorized\u001b[0;34m(p2p, evecs_x, evecs_y, evecs_trans_x, evecs_trans_y, verts_mask_y)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpointmap2Pyx_vectorized\u001b[39m(p2p, evecs_x, evecs_y, evecs_trans_x, evecs_trans_y, verts_mask_y):\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    Convert point-to-point mapping to the permutation matrix.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m        torch.tensor: permutation matrix of shape [B, V_y, V_x].\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     Cxy \u001b[38;5;241m=\u001b[39m \u001b[43mpointmap2Cxy_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp2p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevecs_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevecs_trans_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverts_mask_y\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    153\u001b[0m     Pyx \u001b[38;5;241m=\u001b[39m evecs_y \u001b[38;5;241m@\u001b[39m Cxy \u001b[38;5;241m@\u001b[39m evecs_trans_x\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Pyx\n",
      "File \u001b[0;32m~/Documents/Humboldt/urssm-replicate/notebook/prototype/../../src/utils/fmap.py:131\u001b[0m, in \u001b[0;36mpointmap2Cxy_vectorized\u001b[0;34m(p2p, evecs_x, evecs_trans_y, verts_mask_y)\u001b[0m\n\u001b[1;32m    129\u001b[0m K \u001b[38;5;241m=\u001b[39m evecs_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    130\u001b[0m index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(p2p, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, K) \u001b[38;5;66;03m# [B, V, K]\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m permuted_evecs_x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevecs_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverts_mask_y\u001b[49m \u001b[38;5;66;03m# permute & mask out invalid rows\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Cxy = Phi_y^T @ Pyx @ Phi_x\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m evecs_trans_y \u001b[38;5;241m@\u001b[39m permuted_evecs_x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (200) must match the size of tensor b (5001) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "from src.utils.fmap import pointmap2Pyx_vectorized\n",
    "\n",
    "Pyx = pointmap2Pyx_vectorized(\n",
    "    p2p=p2p,\n",
    "    evecs_x = data['first']['evecs'],\n",
    "    evecs_y = data['second']['evecs'],\n",
    "    evecs_trans_x = data['first']['evecs_trans'],\n",
    "    evecs_trans_y = data['second']['evecs_trans'],\n",
    "    verts_mask_y=data['second']['verts_mask'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5eda04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs_x = data['first']['evecs']\n",
    "evecs_y = data['second']['evecs']\n",
    "evecs_trans_x = data['first']['evecs_trans']\n",
    "evecs_trans_y = data['second']['evecs_trans']\n",
    "verts_mask_y=data['second']['verts_mask']\n",
    "\n",
    "K = evecs_x.shape[-1]\n",
    "index = torch.clamp(p2p, min=0).unsqueeze(-1).expand(-1, -1, K) # [B, V, K]\n",
    "permuted_evecs_x = torch.gather(evecs_x, dim=1, index=index) * verts_mask_y.unsqueeze(-1) # permute & mask out invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c908d8bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (200) must match the size of tensor b (5001) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(evecs_x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, index\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverts_mask_y\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (200) must match the size of tensor b (5001) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "p = torch.gather(evecs_x, dim=1, index=index)\n",
    "p * verts_mask_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e23f2319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5001])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verts_mask_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b6356e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
